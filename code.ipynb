{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('data_YesBank_StockPrices.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning"
      ],
      "metadata": {
        "id": "HKRPVO098z4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(6, 3))\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
        "plt.title('Visualizing Missing Values Using Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for col in df.columns:\n",
        "    print(f\"{col} have {df[col].nunique()} unique values\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the type of col 'Date' to datetime64[ns] format\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the updated datatype of col 'Date'\n",
        "df['Date'].dtypes"
      ],
      "metadata": {
        "id": "zt1fJnivVm2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sorting the df chronologically (if not sorted earlier)\n",
        "df = df.sort_values('Date').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "VqvHTO5uVmk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Range of Date is : {df['Date'].min()} , {df['Date'].max()}\")"
      ],
      "metadata": {
        "id": "UPNXS7NyVmiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding new col 'Year' 'Month' for better understanding\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month"
      ],
      "metadata": {
        "id": "wX9UNRkYVmfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking whether new columns are added successfully or not\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "0w_v0fhSVuC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as we added new cols 'Year' and 'Month' we can drop the col 'Date'\n",
        "df.drop('Date',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "dCCZpZaPVvt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "Z_b8eT1GVvh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Vizualization"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scatter Plot"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Relation between 'Close' and 'Open'\n",
        "plt.subplot(2, 3, 1)\n",
        "sns.scatterplot(x='Open', y='Close', data=df)\n",
        "plt.title('Open vs Close')\n",
        "\n",
        "# Relation between 'Close' and 'Low'\n",
        "plt.subplot(2, 3, 2)\n",
        "sns.scatterplot(x='Low', y='Close', data=df)\n",
        "plt.title('Low vs Close')\n",
        "\n",
        "# Relation between 'Close' and 'High'\n",
        "plt.subplot(2, 3, 3)\n",
        "sns.scatterplot(x='High', y='Close', data=df)\n",
        "plt.title('High vs Close')\n",
        "\n",
        "# Relation between 'Close' and 'Month'\n",
        "plt.subplot(2, 3, 4)\n",
        "sns.scatterplot(x='Month', y='Close', data=df)\n",
        "plt.title('Month vs Close')\n",
        "\n",
        "# Relation between 'Close' and 'Month'\n",
        "plt.subplot(2, 3, 5)\n",
        "sns.scatterplot(x='Year', y='Close', data=df)\n",
        "plt.title('Year vs Close')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Line Plot"
      ],
      "metadata": {
        "id": "E5egW9VAloB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calulating the average Close and Open price\n",
        "yearly_avg = df.groupby('Year')[['Close','Open']].mean().reset_index()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.lineplot(data=yearly_avg, x='Year', y='Close', marker='o', color='blue',label='closing price')\n",
        "sns.lineplot(data=yearly_avg, x='Year', y='Open', marker='o', color='green',label='opening price')\n",
        "plt.title('Yearly trend')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Avg Close Price')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VOXCLhynlmvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Box plot"
      ],
      "metadata": {
        "id": "1vqixWXJ-Ixd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, col in enumerate(df.columns[:4]):\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    sns.boxplot(x=df[col], color='skyblue')\n",
        "    plt.title(f'Box Plot of {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zZS6ZJiw-Ixe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Heapmap"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(df[['Open', 'High', 'Low', 'Month','Year' ,'Close']].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Pair Plot"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "selected_features = ['Open','Low','High','Year','Month','Close']\n",
        "sns.pairplot(df, vars=selected_features)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis Testing"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement 1-\n",
        "\n",
        "Null Hypothesis (H₀): The mean of Open prices = mean of Close prices\n",
        "\n",
        "Alternative Hypothesis (H₁): The mean of Open prices ≠ mean of Close prices"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Paired sample t-test\n",
        "t_stat, p_value = ttest_rel(df['Open'], df['Close'])\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Conclusion\n",
        "if p_value < alpha:\n",
        "    print(\"Reject H0: No significant difference between Open and Close price means.\")\n",
        "else:\n",
        "    print(\"Fail to reject H0: There is a significant difference between Open and Close price means.\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement 2-\n",
        "\n",
        "Null Hypothesis (H0): There is no significant difference in the mean closing price before and after the 2018 fraud case.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant difference in the mean closing price before and after the 2018 fraud case."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# split the data into before and after 2018\n",
        "before_2018 = df[df['Year'] < 2018]['Close']\n",
        "after_2018 = df[df['Year'] >= 2018]['Close']\n",
        "\n",
        "# perfoming independent t-test\n",
        "t_stat, p_value = ttest_ind(before_2018, after_2018, equal_var=False)\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# significance level\n",
        "alpha = 0.05\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject H0: Significant difference in mean closing prices before and after 2018.\")\n",
        "else:\n",
        "    print(\"Fail to reject H0: No significant difference in mean closing prices before and after 2018.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement 3 -\n",
        "\n",
        "Null Hypothesis (H0): The average daily price range (High - Low) is less than or equal to a certain threshold.\n",
        "\n",
        "Alternative Hypothesis (H1): The average daily price range is greater than a certain threshold."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# Calculate daily price range\n",
        "df['Price_Range'] = df['High'] - df['Low']\n",
        "\n",
        "# Perform one-sample t-test (test against value = 5)\n",
        "t_stat, p_value = ttest_1samp(df['Price_Range'], 5)\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value (two-tailed): {p_value}\")\n",
        "\n",
        "# Convert to one-tailed p-value for H1: mean > 5\n",
        "p_value_one_tailed = p_value / 2\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Conclusion\n",
        "if t_stat > 0 and p_value_one_tailed < alpha:\n",
        "    print(\"Reject H0: The average daily price range is significantly greater than 5.\")\n",
        "else:\n",
        "    print(\"Fail to reject H0: No significant evidence that average range exceeds 5.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering & Data Pre-processing"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Outliers"
      ],
      "metadata": {
        "id": "_ey9jzB0-N5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making copy of dataset\n",
        "df1 = df.copy()\n",
        "\n",
        "# Define a function to remove outliers using IQR\n",
        "def remove_outliers_iqr(df, columns):\n",
        "    for col in columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Filter out rows where values are outside the IQR bounds\n",
        "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "\n",
        "    return df\n",
        "\n",
        "# List of numeric columns to check for outliers\n",
        "cols_to_check = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "# Apply the function\n",
        "df = remove_outliers_iqr(df, cols_to_check)\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Closing price from the previous trading day\n",
        "df['Close_Lag_1'] = df['Close'].shift(1)\n",
        "\n",
        "# Daily Open-Close difference\n",
        "df['Daily_Open_Close_Diff'] = df['Close'] - df['Open']\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Close_Lag_1 will have NaN in the first row since there's no previous day.\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "v-mWA9q9_rW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant features\n",
        "features = ['Open', 'High', 'Low', 'Close_Lag_1', 'Price_Range', 'Daily_Open_Close_Diff']\n",
        "\n",
        "# Calculate Pearson correlation with 'Close'\n",
        "correlations = df[features + ['Close']].corr()['Close'].drop('Close')\n",
        "\n",
        "print(correlations)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the skrewness of newly added features\n",
        "for i, col in enumerate(df.columns[6:]):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    sns.histplot(df[col], kde=True)\n",
        "    plt.title(f'{col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9ABn1LNYHUN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log Transform - needed when dats is skewed\n",
        "df['Open_log'] = np.log1p(df['Open'])\n",
        "df['High_log'] = np.log1p(df['High'])\n",
        "df['Low_log'] = np.log1p(df['Low'])\n",
        "df['Close_log'] = np.log1p(df['Close'])\n",
        "df['Price_Range_log'] = np.log1p(df['Price_Range'])\n",
        "df['Close_Lag_1_log'] = np.log1p(df['Close_Lag_1'])\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "bY1VH_qWHUIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Use log-transformed features\n",
        "features_to_scale = ['Open_log','High_log','Low_log','Close_log','Price_Range_log','Close_Lag_1_log']\n",
        "\n",
        "# standardization of log-transformed features\n",
        "scaler = StandardScaler()\n",
        "df = df.copy()\n",
        "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
        "\n",
        "# Check the result\n",
        "df.head()"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data into 80:20 proportion\n",
        "\n",
        "# Importing Library\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features for Linear regression ML Model\n",
        "X = df[['Open_log', 'High_log', 'Low_log', 'Close_Lag_1_log']]\n",
        "y = df['Close_log']\n",
        "\n",
        "# split the dataset - Linear regression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42  )\n",
        "\n",
        "# Features for Random Forest Regressor ML Model\n",
        "X_rf = df[['Open', 'High', 'Low', 'Close_Lag_1']]\n",
        "y_rf = df['Close']\n",
        "\n",
        "# split the dataset - Random forest\n",
        "X_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42  )\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Linear Regression**\n",
        "\n",
        "*Input features:* Open Price , High Price , Low Price after log transformation and scaling\n",
        "\n",
        "*Target feature:* Close Price\n",
        "\n",
        "In this model we predict Close_log (log transformation value of close price) and then we apply inverse log to get actual Close price.\n",
        "\n"
      ],
      "metadata": {
        "id": "ELFbHp70QmBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Liraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Initialize and train the Linear Regression model\n",
        "model_reg = LinearRegression()\n",
        "\n",
        "# Fit the Algorithm\n",
        "model_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_log = model_reg.predict(X_test)\n",
        "\n",
        "# Apply inverse logarithm to get Close price\n",
        "predicted_close_price = np.exp(y_pred_log)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "mse = mean_squared_error(y_test, y_pred_log)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred_log)\n",
        "\n",
        "print(\"R² Score : \",r2)\n",
        "print(\"MSE : \", mse)\n",
        "print(\"RMSE : \", rmse)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Random Forest**\n",
        "\n",
        "*Input features:* Open Price , High Price , Low Price\n",
        "\n",
        "*Target feature:* Close Price\n",
        "\n",
        "In this model we predict Close Price directly\n",
        "\n"
      ],
      "metadata": {
        "id": "K3hRE6wr_nYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Initialize and train the model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_rf_train, y_rf_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_rf = rf_model.predict(X_rf_test)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate performance\n",
        "mse_rf = mean_squared_error(y_rf_test, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mse_rf)\n",
        "r2_rf = r2_score(y_rf_test, y_pred_rf)\n",
        "\n",
        "print(f\"Random Forest - MSE: {mse_rf:.2f}\")\n",
        "print(f\"Random Forest - RMSE: {rmse_rf:.2f}\")\n",
        "print(f\"Random Forest - R² Score: {r2_rf:.2f}\")"
      ],
      "metadata": {
        "id": "te8rkdXctEhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross Validation"
      ],
      "metadata": {
        "id": "7mh45CHs_9xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "Coyc-m9AAehB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression"
      ],
      "metadata": {
        "id": "5DdJgL2GADs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 k-fold\n",
        "r2_score = cross_val_score(model_reg, X, y, cv=5, scoring='r2')\n",
        "\n",
        "# display\n",
        "print(\"Cross-Validation R2 Scores:\", r2_score)\n",
        "print(\"Average R2 Score:\", r2_score.mean())"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "IoOPg9EOAIj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 k-fold\n",
        "r2_score_rf = cross_val_score(rf_model, X_rf, y_rf, cv=5, scoring='r2')\n",
        "\n",
        "# displaying scores\n",
        "print(\"Cross-Validation R2 Scores:\", r2_score_rf)\n",
        "print(\"Average R2 Score:\", r2_score_rf.mean())"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Choosen Model**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Linear Regression model with log transformation as the final prediction model. Because -\n",
        "\n",
        "* It achieved a higher average R² Score (0.9744) during cross-validation than Random Forest (0.9350).\n",
        "* The data showed a strong linear relationship between input features (Open, High, Low, etc.) and Close, which suits linear models well.\n",
        "* Model interpretability is crucial for business reporting, and Linear Regression provides clear coefficient explanations, which Random Forest lacks."
      ],
      "metadata": {
        "id": "MXS6evTtAWMP"
      }
    }
  ]
}