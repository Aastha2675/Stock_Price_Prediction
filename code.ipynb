{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name  - Yes Bank**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression/Machine Learning\n",
        "##### **Contribution**    - Individual"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focuses on building a machine learning model to predict the closing stock price based on historical stock data. The dataset includes monthly stock records with variables such as Open, High, Low, and Close prices. The main goal was to build a robust, accurate, and interpretable predictive model that could assist investors, analysts, and businesses in making data-driven financial decisions.\n",
        "\n",
        "\n",
        "*1. Data Understanding and Preprocessing:*\n",
        "   * The dataset comprised 185 records, each with Date, Open, High, Low, and Close columns.\n",
        "   * All columns were in appropriate data types, though Date was converted into a datetime format for better time-based analysis.\n",
        "   * From the Date, we extracted new features: Year and Month, enabling us to study seasonal and yearly trends.\n",
        "\n",
        "\n",
        "*2. Feature Engineering :* To enhance the model's learning, several new features were created:\n",
        "   * Close_Lag_1: Previous month's closing price\n",
        "   * Daily_Open_Close_Diff: Difference between Open and Close prices\n",
        "   * Price_Range: High − Low for the month\n",
        "\n",
        "These features helped capture momentum and volatility patterns, which are key indicators in stock price movement.\n",
        "\n",
        "\n",
        "*3. Exploratory Data Analysis :*\n",
        "   * Strong positive linear relationships between Close and the features Open, High, and Low.\n",
        "   * Month and Year had weaker linear correlation but indicated potential seasonal effects.\n",
        "   * Data was right-skewed, leading us to apply a log transformation to the Close variable to normalize the distribution and stabilize variance.\n",
        "\n",
        "Visualization tools such as scatter plots, histograms, heatmaps, and pair plots were used to understand distributions, correlations, and outliers.\n",
        "\n",
        "\n",
        "*4. Model Building and Evaluation :*\n",
        "Two models were trained and evaluated -\n",
        "  * Linear Regression (with log-transformed target)\n",
        "  * Random Forest Regressor\n",
        "\n",
        "Linear Regression - Performed well due to the data's linear relationships.Achieved an R² Score of 0.983 (on test split), and 0.974 (avg. across 5-fold CV).RMSE: ~0.11 (log scale), showing low prediction error.Highly interpretable, making it suitable for business insights.\n",
        "\n",
        "Random Forest : Better at capturing non-linear patterns. Test split R²: 0.97, but 5-fold CV average R²: 0.935, indicating slightly less stability. Less interpretable than linear regression.\n",
        "\n",
        "\n",
        "*5. Model Evaluation Metrics Used :*\n",
        "  * R² Score: Explained variance; measures accuracy of prediction.\n",
        "  * Mean Squared Error (MSE): Penalizes larger errors more.\n",
        "  * Root Mean Squared Error (RMSE): Indicates average prediction error in the same scale as actual values.\n",
        "\n",
        "Cross-validation ensured the model wasn't overfitting and performed consistently across different splits.\n",
        "\n",
        "\n",
        "*6. Insights and Business Impact*\n",
        "  * The closing price is highly influenced by Open, High, and Low prices, which supports using regression-based models.\n",
        "  * The model can help forecast future prices, allowing businesses to plan better and investors to assess risk.\n",
        "  * Incorporating feature engineering (e.g., lag variables) significantly improved model performance."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[https://github.com/Aastha2675/Stock_Price_Prediction](https://github.com/Aastha2675/Stock_Price_Prediction)"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stock prices are highly volatile and influenced by various factors. In the case of Yes Bank, events like the 2018 fraud case led to sharp fluctuations. Accurately predicting the monthly closing stock price is challenging yet essential for investors and analysts. This project addresses the problem by using historical stock data to build a machine learning model that forecasts closing prices and aids decision-making."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Solution***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('data_YesBank_StockPrices.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(6, 3))\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
        "plt.title('Visualizing Missing Values Using Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a monthly time series dataset containing historical stock price data for Yes Bank.\n",
        "\n",
        "*Dataset Structure:* 185 rows and 5 columns\n",
        "  * Date\n",
        "  * Open - Price at the beginning of the month\n",
        "  * High - Highest price in that month\n",
        "  * Low - Lowest price in that month\n",
        "  * Close - Price at the end of the month\n",
        "\n",
        "*Datatype of columns:* Date: Object type, Open, High, Low, Close: All are float64, representing monthly stock prices.\n",
        "\n",
        "There are no missing or duplicate values, the dataset is already clean and ready for modeling after minor preprocessing."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All four are continuous numerical features, and the high standard deviation shows significant volatility in Yes Bank’s stock price over time.\n",
        "\n",
        "1. Open - Opening stock price for the month. Ranges from ₹10 to ₹369.95. Median (50%) is ₹62.98.\n",
        "\n",
        "2. High - Highest stock price during the month. Goes up to ₹404. Indicates peak market value.\n",
        "\n",
        "3. Low - Lowest stock price in the month. Shows market downside, ranging from ₹5.55 to ₹345.50.\n",
        "\n",
        "4. Close - Final stock price at month end. Median is ₹62.54, max is ₹367.90."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for col in df.columns:\n",
        "    print(f\"{col} have {df[col].nunique()} unique values\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date has 185 unique values, confirming that each row represents a unique month.\n",
        "\n",
        "Other variables have high uniqueness (close to total rows), so they are not categorical, they're all numerical and continuous."
      ],
      "metadata": {
        "id": "muYBERVdVhSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the type of col 'Date' to datetime64[ns] format\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the updated datatype of col 'Date'\n",
        "df['Date'].dtypes"
      ],
      "metadata": {
        "id": "zt1fJnivVm2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sorting the df chronologically (if not sorted earlier)\n",
        "df = df.sort_values('Date').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "VqvHTO5uVmk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Range of Date is : {df['Date'].min()} , {df['Date'].max()}\")"
      ],
      "metadata": {
        "id": "UPNXS7NyVmiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding new col 'Year' 'Month' for better understanding\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month"
      ],
      "metadata": {
        "id": "wX9UNRkYVmfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking whether new columns are added successfully or not\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "0w_v0fhSVuC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as we added new cols 'Year' and 'Month' we can drop the col 'Date'\n",
        "df.drop('Date',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "dCCZpZaPVvt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "Z_b8eT1GVvh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date column was converted to datetime, sorted, split into year/month, and original column dropped.\n",
        "\n",
        "This manipulations made the dataset clean, chronologically ordered, and ready for time-series or seasonal analysis, such as checking how the closing price varies across years or months."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1\n",
        "\n",
        "Scatter Plot"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Relation between 'Close' and 'Open'\n",
        "plt.subplot(2, 3, 1)\n",
        "sns.scatterplot(x='Open', y='Close', data=df)\n",
        "plt.title('Open vs Close')\n",
        "\n",
        "# Relation between 'Close' and 'Low'\n",
        "plt.subplot(2, 3, 2)\n",
        "sns.scatterplot(x='Low', y='Close', data=df)\n",
        "plt.title('Low vs Close')\n",
        "\n",
        "# Relation between 'Close' and 'High'\n",
        "plt.subplot(2, 3, 3)\n",
        "sns.scatterplot(x='High', y='Close', data=df)\n",
        "plt.title('High vs Close')\n",
        "\n",
        "# Relation between 'Close' and 'Month'\n",
        "plt.subplot(2, 3, 4)\n",
        "sns.scatterplot(x='Month', y='Close', data=df)\n",
        "plt.title('Month vs Close')\n",
        "\n",
        "# Relation between 'Close' and 'Month'\n",
        "plt.subplot(2, 3, 5)\n",
        "sns.scatterplot(x='Year', y='Close', data=df)\n",
        "plt.title('Year vs Close')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Questions"
      ],
      "metadata": {
        "id": "5pFvkrFPYms3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  It help us visually inspect whether a linear relationship exists between varibales\n",
        "*  It helps to check data is evenly spread, clustered, or skewed, which can affect the model’s accuracy.\n",
        "*  Show if there are any outliers, which might need special handling or removal.\n"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Input features - Open, Low, and High show a strong positive linear relationship with the Close price.\n",
        "* Input features - Month and Year does not show any linear relation with the Close price.\n",
        "* It does not showing major outliers or abnormal patterns."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 3. Will the gained insights help creating a positive business impact?Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights help in positive business impact. The visualizations clearly show that the variables Open, High, and Low have a strong positive linear relationship with the Close price. This confirms that these features are reliable predictors for building a regression model to forecast stock closing prices accurately. Month and Year show weak relation, which may reduce model accuracy if not handled properly.\n"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2\n",
        "\n",
        "Line Plot"
      ],
      "metadata": {
        "id": "E5egW9VAloB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calulating the average Close and Open price\n",
        "yearly_avg = df.groupby('Year')[['Close','Open']].mean().reset_index()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.lineplot(data=yearly_avg, x='Year', y='Close', marker='o', color='blue',label='closing price')\n",
        "sns.lineplot(data=yearly_avg, x='Year', y='Open', marker='o', color='green',label='opening price')\n",
        "plt.title('Yearly trend')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Avg Close Price')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VOXCLhynlmvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Questions"
      ],
      "metadata": {
        "id": "z7ltSCqKpDpr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "R0Lp21U6pE7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  To observe the yearly trend for open price and close price\n",
        "\n"
      ],
      "metadata": {
        "id": "-C6x_s1epK-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "6f_TKv12pT6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Both Opening and Closing prices show a consistent upward trend from 2005 to 2017, peaking in 2017.\n",
        "\n",
        "* A sharp decline is seen after 2018, indicating a possible market correction or external shock (e.g., fraud, crash).\n",
        "\n",
        "* Opening and Closing prices closely follow each other, confirming strong correlation."
      ],
      "metadata": {
        "id": "TyX4ZG3AyI93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 3. Will the gained insights help creating a positive business impact?Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "2seeqRpwpjzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Positive Impact: The steady rise till 2017 indicates growth and investor confidence—useful for strategic investments.\n",
        "\n",
        "* Negative Growth Insight: Post-2018 decline warns businesses/investors to analyze risks or events affecting stock performance."
      ],
      "metadata": {
        "id": "L1JcoeqkyKQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3\n",
        "\n",
        "Box plot"
      ],
      "metadata": {
        "id": "1vqixWXJ-Ixd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, col in enumerate(df.columns[:4]):\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    sns.boxplot(x=df[col], color='skyblue')\n",
        "    plt.title(f'Box Plot of {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zZS6ZJiw-Ixe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Questions"
      ],
      "metadata": {
        "id": "m0DjLfnd-Ixf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "qf7W2wl2-Ixf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  To visualize the outlier\n",
        "\n"
      ],
      "metadata": {
        "id": "SLnGh01N-Ixf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "91KywdeQ-Ixg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* All four variables (Open, High, Low, Close) show positive skew with outliers on the higher end.\n",
        "\n",
        "* The distribution is not symmetric; majority of data lies in the lower range.\n",
        "\n",
        "* Outliers are present but consistent across features, likely representing market spikes."
      ],
      "metadata": {
        "id": "Nl5_Dv-u-Ixg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 3. Will the gained insights help creating a positive business impact?Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "V6WCfeen-Ixg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Positive Insight: Stable interquartile ranges (IQR) show a predictable core pattern useful for baseline modeling.\n",
        "\n",
        "* Negative Insight: Outliers may cause model bias—need to handle them for better predictions."
      ],
      "metadata": {
        "id": "eqkP8ggj-Ixg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4\n",
        "\n",
        "Heapmap"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(df[['Open', 'High', 'Low', 'Month','Year' ,'Close']].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* It clearly visualizes the strength and direction of correlation between variables.\n",
        "* Helps to identify highly correlated features and avoid multicollinearity in regression.\n"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  Close has a very strong positive correlation with Open (0.98), High (0.99), and Low (1.0).\n",
        "* Month and Year show very weak or negative correlation with Close.\n",
        "\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 3. Will the gained insights help creating a positive business impact?Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, selecting features like Open, High, and Low will enhance prediction accuracy for closing prices.\n",
        "However, since these are strongly inter-correlated, it may lead to multicollinearity, which can affect model stability.\n",
        "Using Month and Year directly may not add value and might dilute model effectiveness."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5\n",
        "\n",
        "Pair Plot"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "selected_features = ['Open','Low','High','Year','Month','Close']\n",
        "sns.pairplot(df, vars=selected_features)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Questions\n"
      ],
      "metadata": {
        "id": "3fX64Kc_ZBC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* It helps visualize pairwise relationships between multiple variables in one view.\n",
        "* Shows linear trends, correlations, and cluster patterns.\n",
        "* Useful to check multicollinearity among predictors before model building.\n",
        "\n"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Strong positive linear relationship between Open, Low, High, and Close\n",
        "* Month and Year show no clear trend with Close.\n",
        "* No major outliers or noisy patterns detected among selected features.\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 3. Will the gained insights help creating a positive business impact?Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, insights support selecting strong predictors (Open, High, Low) to build a reliable model for forecasting closing prices, which helps in better investment planning. Weak patterns from Year/Month may reduce accuracy if used without proper encoding, but don’t directly indicate negative growth."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "UvH90T3K5MmX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Null Hypothesis (H₀): The mean of Open prices = mean of Close prices\n",
        "\n",
        "Alternative Hypothesis (H₁): The mean of Open prices ≠ mean of Close prices"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Paired sample t-test\n",
        "t_stat, p_value = ttest_rel(df['Open'], df['Close'])\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Conclusion\n",
        "if p_value < alpha:\n",
        "    print(\"Reject H0: There is a significant difference between Open and Close price means.\")\n",
        "else:\n",
        "    print(\"Fail to reject H0: No significant difference between Open and Close price means.\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Questions"
      ],
      "metadata": {
        "id": "09eihoqyhs37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "paired t-test"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because Open and Close prices are related for each time point, the paired t-test is appropriate. It checks whether the average difference between Open and Close is statistically significant."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in the mean closing price before and after the 2018 fraud case.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant difference in the mean closing price before and after the 2018 fraud case."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# split the data into before and after 2018\n",
        "before_2018 = df[df['Year'] < 2018]['Close']\n",
        "after_2018 = df[df['Year'] >= 2018]['Close']\n",
        "\n",
        "# perfoming independent t-test\n",
        "t_stat, p_value = ttest_ind(before_2018, after_2018, equal_var=False)\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# significance level\n",
        "alpha = 0.05\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject H0: Significant difference in mean closing prices before and after 2018.\")\n",
        "else:\n",
        "    print(\"Fail to reject H0: No significant difference in mean closing prices before and after 2018.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Question"
      ],
      "metadata": {
        "id": "Kq58vS_x1DhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Independent two-sample t-test"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to compare the mean closing prices before and after 2018 fraud case.\n",
        "The Close price is continuous numeric data, and we are comparing means across two different time periods before and after 2018.Hence, the t-test is the most appropriate and statistically valid choice for this comparison."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): The average daily price range (High - Low) is less than or equal to a certain threshold.\n",
        "\n",
        "Alternative Hypothesis (H1): The average daily price range is greater than a certain threshold."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# Calculate daily price range\n",
        "df['Price_Range'] = df['High'] - df['Low']\n",
        "\n",
        "# Perform one-sample t-test (test against value = 5)\n",
        "t_stat, p_value = ttest_1samp(df['Price_Range'], 5)\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value (two-tailed): {p_value}\")\n",
        "\n",
        "# Convert to one-tailed p-value for H1: mean > 5\n",
        "p_value_one_tailed = p_value / 2\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Conclusion\n",
        "if t_stat > 0 and p_value_one_tailed < alpha:\n",
        "    print(\"Reject H0: The average daily price range is significantly greater than 5.\")\n",
        "else:\n",
        "    print(\"Fail to reject H0: No significant evidence that average range exceeds 5.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "one-sample, one-tailed t-test."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we are testing a sample mean (High - Low) against a specific threshold value (Here Rs.5)\n",
        "Since we are only interested in whether it's greater than 5 one-tailed one-sample t-test will work best .\n"
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No need to handle missing values"
      ],
      "metadata": {
        "id": "75LkwsXYEPWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making copy of dataset\n",
        "df1 = df.copy()\n",
        "\n",
        "# Define a function to remove outliers using IQR\n",
        "def remove_outliers_iqr(df, columns):\n",
        "    for col in columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Filter out rows where values are outside the IQR bounds\n",
        "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "\n",
        "    return df\n",
        "\n",
        "# List of numeric columns to check for outliers\n",
        "cols_to_check = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "# Apply the function\n",
        "df = remove_outliers_iqr(df, cols_to_check)\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IQR (Interquartile Range) Method - It detects outliers as values below Q1 - 1.5×IQR or above Q3 + 1.5×IQR.\n",
        "\n",
        "Why Used: This method is robust to non-normal distributions and works by defining a range around the median. Data points outside 1.5\n",
        "timesIQR below the first quartile (Q_1) or above the third quartile (Q_3) are considered outliers."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Closing price from the previous trading day\n",
        "df['Close_Lag_1'] = df['Close'].shift(1)\n",
        "\n",
        "# Daily Open-Close difference\n",
        "df['Daily_Open_Close_Diff'] = df['Close'] - df['Open']\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Close_Lag_1 will have NaN in the first row since there's no previous day.\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "v-mWA9q9_rW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant features\n",
        "features = ['Open', 'High', 'Low', 'Close_Lag_1', 'Price_Range', 'Daily_Open_Close_Diff']\n",
        "\n",
        "# Calculate Pearson correlation with 'Close'\n",
        "correlations = df[features + ['Close']].corr()['Close'].drop('Close')\n",
        "\n",
        "print(correlations)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To identify which of these features might be most useful for predicting 'Close' price, I've calculated the Pearson correlation coefficient between each feature and the 'Close' price. Features with higher absolute correlation values are generally considered more relevant."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Low**, **High**, **Close_Lag_1**, and **Open** show extremely high positive correlations with the 'Close' price. This indicates they are very strong indicators, which is typical for stock data where prices are highly correlated day-to-day."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, Data transformation is needed because -\n",
        "\n",
        "\n",
        "* Different Scales : Features like Open, High, and Low are on large numeric scales. This scale difference can bias models like linear regression, KNN, SVM, etc.\n",
        "* Skewness : From histograms, the variables appeared right-skewed. Skewed data can violate model assumptions (especially linear regression) and lead to poor performance.\n",
        "* Improve Model Convergence : Models like gradient descent (used in linear regression) converge faster with normalized or standardized inputs.\n",
        "\n"
      ],
      "metadata": {
        "id": "Vt6v2emaF08M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the skrewness of newly added features\n",
        "for i, col in enumerate(df.columns[6:]):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    sns.histplot(df[col], kde=True)\n",
        "    plt.title(f'{col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9ABn1LNYHUN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log Transform - needed when dats is skewed\n",
        "df['Open_log'] = np.log1p(df['Open'])\n",
        "df['High_log'] = np.log1p(df['High'])\n",
        "df['Low_log'] = np.log1p(df['Low'])\n",
        "df['Close_log'] = np.log1p(df['Close'])\n",
        "df['Price_Range_log'] = np.log1p(df['Price_Range'])\n",
        "df['Close_Lag_1_log'] = np.log1p(df['Close_Lag_1'])\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "bY1VH_qWHUIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Use log-transformed features\n",
        "features_to_scale = ['Open_log','High_log','Low_log','Close_log','Price_Range_log','Close_Lag_1_log']\n",
        "\n",
        "# standardization of log-transformed features\n",
        "scaler = StandardScaler()\n",
        "df = df.copy()\n",
        "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
        "\n",
        "# Check the result\n",
        "df.head()"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here Standardscaler is used because it’s mathematically aligned with linear regression's assumptions and ensures proper coefficient learning and it is Preferred for Linear Regression, it transforms features to have: Mean = 0 and Standard deviation = 1.\n"
      ],
      "metadata": {
        "id": "gRw_8jqTKY4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, dimensionality reduction is not required for current setup since the number of features is small and each has clear predictive value."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Library\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features for Linear regression ML Model\n",
        "X = df[['Open_log', 'High_log', 'Low_log', 'Close_Lag_1_log']]\n",
        "y = df['Close_log']\n",
        "\n",
        "# split the dataset - Linear regression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42  )\n",
        "\n",
        "# Features for Random Forest Regressor ML Model\n",
        "X_rf = df[['Open', 'High', 'Low', 'Close_Lag_1']]\n",
        "y_rf = df['Close']\n",
        "\n",
        "# split the dataset - Random forest\n",
        "X_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42  )\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 80:20 ratio - 80% train, 20% test"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**No**, dataset is not imbalanced as there are no classes or labels to balance."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model 1 - Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Liraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Initialize and train the Linear Regression model\n",
        "model_reg = LinearRegression()\n",
        "\n",
        "# Fit the Algorithm\n",
        "model_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_log = model_reg.predict(X_test)\n",
        "\n",
        "# Apply inverse logarithm to get Close price\n",
        "predicted_close_price = np.exp(y_pred_log)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "mse = mean_squared_error(y_test, y_pred_log)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred_log)\n",
        "\n",
        "print(\"R² Score : \",r2)\n",
        "print(\"MSE : \", mse)\n",
        "print(\"RMSE : \", rmse)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ML Model Used: Linear Regression**\n",
        "\n",
        "*Input features:* Open Price , High Price , Low Price after log transformation and scaling\n",
        "\n",
        "*Target feature:* Close Price\n",
        "\n",
        "In this model we predict Close_log (log transformation value of close price) and then we apply inverse log to get actual Close price.\n",
        "\n",
        "**Evaluation metric Score Chart:**\n",
        "\n",
        "*R² Score :* The model explains 98.38% of the variance in the closing price. This is very high, indicating excellent predictive performance.\n",
        "\n",
        "*MSE :* The average squared error between predicted and actual (log-transformed) values is very low.\n",
        "\n",
        "*RMSE :* The average prediction error (in log scale) is small. When back-transformed, this reflects minimal deviation from actual values.\n"
      ],
      "metadata": {
        "id": "ELFbHp70QmBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 5 k-fold\n",
        "r2_score = cross_val_score(model_reg, X, y, cv=5, scoring='r2')\n",
        "\n",
        "# display\n",
        "print(\"Cross-Validation R2 Scores:\", r2_score)\n",
        "print(\"Average R2 Score:\", r2_score.mean())"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-fold Cross-validation Technique :**\n",
        "\n",
        "It helps us check how well a model generalizes to unseen data by splitting the dataset into multiple training/testing folds.\n",
        "\n",
        "While the single split had a slightly higher R², the cross-validation average gives a more realistic and trustworthy estimate of your model’s performance on unseen data.\n"
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yes**,\n",
        "after applying the K-Fold Cross-Validation with 5 folds, we found that the **average R² Score is 0.97**, which indicates that the model generalizes well and **maintains a high level of accuracy across different subsets of the data**. This confirms the model's reliability and performance stability.\n"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model 2 - Random Forest"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Initialize and train the model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_rf_train, y_rf_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_rf = rf_model.predict(X_rf_test)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate performance\n",
        "mse_rf = mean_squared_error(y_rf_test, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mse_rf)\n",
        "r2_rf = r2_score(y_rf_test, y_pred_rf)\n",
        "\n",
        "print(f\"Random Forest - MSE: {mse_rf:.2f}\")\n",
        "print(f\"Random Forest - RMSE: {rmse_rf:.2f}\")\n",
        "print(f\"Random Forest - R² Score: {r2_rf:.2f}\")"
      ],
      "metadata": {
        "id": "te8rkdXctEhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation\n",
        "# importing libraries\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 5 k-fold\n",
        "r2_score_rf = cross_val_score(rf_model, X_rf, y_rf, cv=5, scoring='r2')\n",
        "\n",
        "# displaying scores\n",
        "print(\"Cross-Validation R2 Scores:\", r2_score_rf)\n",
        "print(\"Average R2 Score:\", r2_score_rf.mean())"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-fold Cross-validation Technique :**\n",
        "\n",
        "It helps us check how well a model generalizes to unseen data by splitting the dataset into multiple training/testing folds.\n",
        "\n",
        "While the single split had a slightly higher R², the cross-validation average gives a more realistic and trustworthy estimate of your model’s performance on unseen data."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not really, after applying the K-Fold Cross-Validation with 5 folds, the Random Forest model achieved an average R² Score of 0.935. While this is slightly lower than the single-split score of 0.97, it is a more reliable indicator of the model's performance on unseen data. This confirms the model's consistency and helps avoid overfitting."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chosen Metrics:**\n",
        "\n",
        "R² Score : Tells how much of the price variation is explained by the model (ideal for regression tasks). A high R² (~0.97) implies strong business reliability.\n",
        "\n",
        "RMSE : Indicates the average prediction error. Useful for understanding real-world impact in price deviation (e.g., ₹7–₹16 error range).\n",
        "\n",
        "MSE : Helps optimize the model by penalizing larger errors more heavily. Valuable in risk-sensitive environments like stock prediction."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Choosen Model :** Linear Regression model with log transformation as the final prediction model. Because -\n",
        "* It achieved a higher average R² Score (0.9744) during cross-validation than Random Forest (0.9350).\n",
        "* The data showed a strong linear relationship between input features (Open, High, Low, etc.) and Close, which suits linear models well.\n",
        "* Model interpretability is crucial for business reporting, and Linear Regression provides clear coefficient explanations, which Random Forest lacks.\n",
        "\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Used: Linear Regression with Log Transformation**\n",
        "\n",
        "We log-transformed the target variable (Close) to normalize the distribution and reduce skewness.\n",
        "\n",
        "After training, predictions were converted back to the original scale using np.exp()."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project aimed to predict stock closing prices using regression. After preprocessing, feature engineering, and testing models, linear regression with log transformation gave the best accuracy and interpretability for reliable forecasts.\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    }
  ]
}